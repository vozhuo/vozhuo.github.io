<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>图神经网络初探 | Vozhuo's Blog</title>
<meta name=keywords content="图神经网络"><meta name=description content="背景
深度学习取得成功的领域主要来源于欧几里得数据（如2维网格的图像和1维序列的文本），但现实生活中还存在大量的非欧几里得数据，如社交网络、电商网络、生物网络和交通网络等。尚未出现对这些数据的有效分析。例如，在电子商务领域，一个基于图的学习系统能够利用用户和产品之间的交互以实现高度精准的推荐。在化学领域，分子被建模为图，新药研发需要测定其生物活性。在论文引用网络中，论文之间通过引用关系互相连接，需要将它们分成不同的类别。"><meta name=author content="Vozhuo"><link rel=canonical href=https://vozhuo.github.io/posts/gnn-view/><link crossorigin=anonymous href=/assets/css/stylesheet.css rel="preload stylesheet" as=style><link rel=icon href=https://vozhuo.github.io/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://vozhuo.github.io/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://vozhuo.github.io/favicon-32x32.png><link rel=apple-touch-icon href=https://vozhuo.github.io/apple-touch-icon.png><link rel=mask-icon href=https://vozhuo.github.io/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><script async src="https://www.googletagmanager.com/gtag/js?id=G-05K3ZTE5YX"></script><script>var doNotTrack=!1;if(!doNotTrack){window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-05K3ZTE5YX",{anonymize_ip:!1})}</script><meta property="og:title" content="图神经网络初探"><meta property="og:description" content="背景
深度学习取得成功的领域主要来源于欧几里得数据（如2维网格的图像和1维序列的文本），但现实生活中还存在大量的非欧几里得数据，如社交网络、电商网络、生物网络和交通网络等。尚未出现对这些数据的有效分析。例如，在电子商务领域，一个基于图的学习系统能够利用用户和产品之间的交互以实现高度精准的推荐。在化学领域，分子被建模为图，新药研发需要测定其生物活性。在论文引用网络中，论文之间通过引用关系互相连接，需要将它们分成不同的类别。"><meta property="og:type" content="article"><meta property="og:url" content="https://vozhuo.github.io/posts/gnn-view/"><meta property="article:section" content="posts"><meta property="article:published_time" content="2019-06-01T19:25:06+08:00"><meta property="article:modified_time" content="2019-06-01T19:25:06+08:00"><meta name=twitter:card content="summary"><meta name=twitter:title content="图神经网络初探"><meta name=twitter:description content="背景
深度学习取得成功的领域主要来源于欧几里得数据（如2维网格的图像和1维序列的文本），但现实生活中还存在大量的非欧几里得数据，如社交网络、电商网络、生物网络和交通网络等。尚未出现对这些数据的有效分析。例如，在电子商务领域，一个基于图的学习系统能够利用用户和产品之间的交互以实现高度精准的推荐。在化学领域，分子被建模为图，新药研发需要测定其生物活性。在论文引用网络中，论文之间通过引用关系互相连接，需要将它们分成不同的类别。"><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"https://vozhuo.github.io/posts/"},{"@type":"ListItem","position":2,"name":"图神经网络初探","item":"https://vozhuo.github.io/posts/gnn-view/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"图神经网络初探","name":"图神经网络初探","description":"背景 深度学习取得成功的领域主要来源于欧几里得数据（如2维网格的图像和1维序列的文本），但现实生活中还存在大量的非欧几里得数据，如社交网络、电商网络、生物网络和交通网络等。尚未出现对这些数据的有效分析。例如，在电子商务领域，一个基于图的学习系统能够利用用户和产品之间的交互以实现高度精准的推荐。在化学领域，分子被建模为图，新药研发需要测定其生物活性。在论文引用网络中，论文之间通过引用关系互相连接，需要将它们分成不同的类别。\n","keywords":["图神经网络"],"articleBody":"背景 深度学习取得成功的领域主要来源于欧几里得数据（如2维网格的图像和1维序列的文本），但现实生活中还存在大量的非欧几里得数据，如社交网络、电商网络、生物网络和交通网络等。尚未出现对这些数据的有效分析。例如，在电子商务领域，一个基于图的学习系统能够利用用户和产品之间的交互以实现高度精准的推荐。在化学领域，分子被建模为图，新药研发需要测定其生物活性。在论文引用网络中，论文之间通过引用关系互相连接，需要将它们分成不同的类别。\n图数据的复杂性对现有机器学习算法提出了重大挑战，因为图数据是不规则的。每张图大小不同、节点无序，一张图中的每个节点都有不同数目的邻近节点，使得一些在图像中容易计算的重要运算（如卷积）不能再直接应用于图。图神经网络（GNN）是一类基于深度学习的处理图域信息的方法。受到深度学习领域进展的驱动，研究人员在设计图神经网络的架构时借鉴了卷积网络、循环网络和深度自编码器的思想。\n类别 图神经网络最终分类为：图卷积网络、图注意力网络、图自编码器、图生成网络和图时空网络。这些网络中，图卷积网络在捕捉架构依存关系上扮演着核心角色。\n图卷积网络 图卷积网络（GCN）是一个对图数据进行操作的神经网络。对于图 G=(V,E)，使用以下特征： 节点特征：每个节点均有其特征，可以用N * E矩阵表示。其中 N 表示节点数，E 表示每个节点的特征数。 图结构特征：图结构上的信息可以用邻接矩阵表示。\n卷积网络从卷积方式上可以分为两种：谱卷积和空间域卷积。基于谱的方法通过从图信号处理的角度引入滤波器来定义图卷积，其中图卷积运算被解释为从图信号中去除噪声。基于空间的方法将图卷积表征为聚合来自近邻的特征信息。\n图注意力网络 GCN结合邻近节点特征的方式和图的结构相关，这局限了训练所得模型在其他图结构上的泛化能力。而注意力机制能够聚焦于对象最重要的部分，几乎成为序列任务中的标配。该机制在机器翻译和自然语言理解等任务中有着广泛的应用。图注意力网络用注意力机制对邻近节点特征加权求和。邻近节点特征的权重完全取决于节点特征，独立于图结构。\n相关模型有图注意力网络（Graph Attention Network，GAT）、门控注意力网络（Gated Attention Network，GAAN）、图注意力模型（Graph Attention Model，GAM）、注意力游走（Attention Walks）。\n图自编码器 图自编码器是一类网络嵌入方法，旨在通过神经网络架构将网络中的节点表征到低维向量空间。典型的解决方案是使用多层感知机作为编码器来获取节点嵌入，解码器重建节点的近邻统计。\n基于 GCN 的自编码器部分有：图自编码器（Graph Auto-encoder，GAE）、对抗正则化图自编码器（Adversarially Regularized Graph Autoencoder，ARGA）。其他变体包括：具备对抗正则化自编码器的网络表征（Network Representations with Adversarially Regularized Autoencoders，NetRA）、用于图表征的深度神经网络（Deep Neural Networks for Graph Representations，DNGR）、结构化深度网络嵌入（Structural Deep Network Embedding，SDNE）、深度递归网络嵌入（Deep Recursive Network Embedding，DRNE）。\n图生成网络 图生成网络的目标是基于一组可观察图来生成图，其中的很多方法都是领域特定的。例如，在分子图生成方面，一些研究将分子图的表征建模为字符串。在自然语言处理中，生成语义图或知识图通常需要一个给定的句子。该领域的方法要么使用 GCN 作为构造块，要么使用不同的架构。\n基于 GCN 的图生成网络包括：分子生成对抗网络（Molecular Generative Adversarial Networks，MolGAN）和深度图生成模型（Deep Generative Models of Graphs，DGMG）；其他图生成网络有 GraphRNN（通过两级循环神经网络使用深度图生成模型）和 NetGAN（结合 LSTM 和 Wasserstein GAN 从基于随机游走的方法中生成图）。\n图时空网络 图时空网络同时捕捉时空图的时间和空间依赖。时空图具备全局图结构，每个节点的输入随着时间而改变。例如在交通网络中，使用每个传感器作为节点来连续记录某条道路的交通流动速度，其中交通网络的边由传感器对之间的距离决定。图时空网络的目标是预测未来节点值或标签，或预测时空图标签。近期研究探索了仅使用 GCN、结合 GCN 和 RNN 或 CNN，以及专用于图结构的循环架构。\n基于 GCN 的图时空网络包括：Diffusion Convolutional Recurrent Neural Network (DCRNN)、CNN-GCN、时空 GCN（Spatial Temporal GCN，ST-GCN）。其他图时空网络有 Structural-RNN，一种循环结构化框架。\n应用 GNN被广泛应用在社交网络、推荐系统、物理系统、化学分子预测、知识图谱、自然语言处理、计算机视觉（场景图生成、动作识别等）、交通预测等领域。\n常用的数据集如下：\n未来方向 加深网络。深度学习的成功在于深度神经架构。但在图网络中，实证研究表明，随着网络层数增加，模型性能急剧下降。这是由于图卷积的影响，因为它本质上推动相邻节点的表示更加接近彼此。堆叠层数越多，节点考虑的邻居个数也会越多，导致最终所有节点的表示会趋向于一致。这导致了一个问题：加深网络是否仍然是学习图结构数据的好策略？\n感受野。节点的感受野是指一组节点，包括中心节点和其近邻节点。有些节点可能只有一个近邻，而有些节点却有数千个近邻。如何选择节点的代表性感受野仍然有待探索。\n可扩展性。当前大部分图神经网络并不能很好地扩展到大规模数据（大型图）上。主要原因是当堆叠一个图卷积的多层时，节点的最终状态涉及其大量近邻节点的隐藏状态，导致反向传播变得非常复杂。\n动态性和异质性。大多数当前的图神经网络都处理静态同质图，即假设图架构是固定的，而且图的节点和边来自同一个来源。然而，这两个假设在很多情况下是不现实的。在社交网络中，一个新人可能会随时加入，而之前就存在的人也可能退出该社交网络。在推荐系统中，产品可能具有不同的类型，而其输出形式也可能不同，也许是文本，也许是图像。\n可解释性。由于图通常与其他学科相关，解释图深度学习模型对于决策问题来说是关键。但是，基于图的深度学习模型比其他黑箱模型更难解释，因为图中的节点和边高度关联。\n参考综述论文：\nGraph Neural Networks: A Review of Methods and Applications. Jie Zhou, Ganqu Cui, Zhengyan Zhang, Cheng Yang, Zhiyuan Liu, Maosong Sun. 2018.\nA Comprehensive Survey on Graph Neural Networks. Zonghan Wu, Shirui Pan, Fengwen Chen, Guodong Long, Chengqi Zhang, Philip S. Yu. 2019.\nDeep Learning on Graphs: A Survey. Ziwei Zhang, Peng Cui, Wenwu Zhu. 2018.\n","wordCount":"158","inLanguage":"en","datePublished":"2019-06-01T19:25:06+08:00","dateModified":"2019-06-01T19:25:06+08:00","author":{"@type":"Person","name":"Vozhuo"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://vozhuo.github.io/posts/gnn-view/"},"publisher":{"@type":"Organization","name":"Vozhuo's Blog","logo":{"@type":"ImageObject","url":"https://vozhuo.github.io/favicon.ico"}}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://vozhuo.github.io accesskey=h title="Vozhuo's Blog (Alt + H)">Vozhuo's Blog</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://vozhuo.github.io/tags/ title=tags><span>tags</span></a></li><li><a href=https://vozhuo.github.io/about/ title=About><span>About</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><div class=breadcrumbs><a href=https://vozhuo.github.io>Home</a>&nbsp;»&nbsp;<a href=https://vozhuo.github.io/posts/>Posts</a></div><h1 class="post-title entry-hint-parent">图神经网络初探</h1><div class=post-meta><span title='2019-06-01 19:25:06 +0800 CST'>2019-06-01</span>&nbsp;·&nbsp;1 min&nbsp;·&nbsp;158 words&nbsp;·&nbsp;Vozhuo</div></header><div class=toc><details><summary accesskey=c title="(Alt + C)"><span class=details>Table of Contents</span></summary><div class=inner><nav id=TableOfContents><ul><li><a href=#背景>背景</a></li><li><a href=#类别>类别</a><ul><li><a href=#图卷积网络>图卷积网络</a></li><li><a href=#图注意力网络>图注意力网络</a></li><li><a href=#图自编码器>图自编码器</a></li><li><a href=#图生成网络>图生成网络</a></li><li><a href=#图时空网络>图时空网络</a></li></ul></li><li><a href=#应用>应用</a></li><li><a href=#未来方向>未来方向</a></li></ul></nav></div></details></div><div class=post-content><h2 id=背景>背景<a hidden class=anchor aria-hidden=true href=#背景>#</a></h2><p>深度学习取得成功的领域主要来源于欧几里得数据（如2维网格的图像和1维序列的文本），但现实生活中还存在大量的非欧几里得数据，如社交网络、电商网络、生物网络和交通网络等。尚未出现对这些数据的有效分析。例如，在电子商务领域，一个基于图的学习系统能够利用用户和产品之间的交互以实现高度精准的推荐。在化学领域，分子被建模为图，新药研发需要测定其生物活性。在论文引用网络中，论文之间通过引用关系互相连接，需要将它们分成不同的类别。</p><p>图数据的复杂性对现有机器学习算法提出了重大挑战，因为图数据是不规则的。每张图大小不同、节点无序，一张图中的每个节点都有不同数目的邻近节点，使得一些在图像中容易计算的重要运算（如卷积）不能再直接应用于图。图神经网络（GNN）是一类基于深度学习的处理图域信息的方法。受到深度学习领域进展的驱动，研究人员在设计图神经网络的架构时借鉴了卷积网络、循环网络和深度自编码器的思想。</p><h2 id=类别>类别<a hidden class=anchor aria-hidden=true href=#类别>#</a></h2><p>图神经网络最终分类为：图卷积网络、图注意力网络、图自编码器、图生成网络和图时空网络。这些网络中，图卷积网络在捕捉架构依存关系上扮演着核心角色。</p><p><img loading=lazy src=/img/gnn-cateogry.png alt></p><h3 id=图卷积网络>图卷积网络<a hidden class=anchor aria-hidden=true href=#图卷积网络>#</a></h3><p>图卷积网络（GCN）是一个对图数据进行操作的神经网络。对于图 G=(V,E)，使用以下特征：
节点特征：每个节点均有其特征，可以用N * E矩阵表示。其中 N 表示节点数，E 表示每个节点的特征数。
图结构特征：图结构上的信息可以用邻接矩阵表示。</p><p>卷积网络从卷积方式上可以分为两种：谱卷积和空间域卷积。基于谱的方法通过从图信号处理的角度引入滤波器来定义图卷积，其中图卷积运算被解释为从图信号中去除噪声。基于空间的方法将图卷积表征为聚合来自近邻的特征信息。</p><h3 id=图注意力网络>图注意力网络<a hidden class=anchor aria-hidden=true href=#图注意力网络>#</a></h3><p>GCN结合邻近节点特征的方式和图的结构相关，这局限了训练所得模型在其他图结构上的泛化能力。而注意力机制能够聚焦于对象最重要的部分，几乎成为序列任务中的标配。该机制在机器翻译和自然语言理解等任务中有着广泛的应用。图注意力网络用注意力机制对邻近节点特征加权求和。邻近节点特征的权重完全取决于节点特征，独立于图结构。</p><p>相关模型有图注意力网络（Graph Attention Network，GAT）、门控注意力网络（Gated Attention Network，GAAN）、图注意力模型（Graph Attention Model，GAM）、注意力游走（Attention Walks）。</p><h3 id=图自编码器>图自编码器<a hidden class=anchor aria-hidden=true href=#图自编码器>#</a></h3><p>图自编码器是一类网络嵌入方法，旨在通过神经网络架构将网络中的节点表征到低维向量空间。典型的解决方案是使用多层感知机作为编码器来获取节点嵌入，解码器重建节点的近邻统计。</p><p>基于 GCN 的自编码器部分有：图自编码器（Graph Auto-encoder，GAE）、对抗正则化图自编码器（Adversarially Regularized Graph Autoencoder，ARGA）。其他变体包括：具备对抗正则化自编码器的网络表征（Network Representations with Adversarially Regularized Autoencoders，NetRA）、用于图表征的深度神经网络（Deep Neural Networks for Graph Representations，DNGR）、结构化深度网络嵌入（Structural Deep Network Embedding，SDNE）、深度递归网络嵌入（Deep Recursive Network Embedding，DRNE）。</p><h3 id=图生成网络>图生成网络<a hidden class=anchor aria-hidden=true href=#图生成网络>#</a></h3><p>图生成网络的目标是基于一组可观察图来生成图，其中的很多方法都是领域特定的。例如，在分子图生成方面，一些研究将分子图的表征建模为字符串。在自然语言处理中，生成语义图或知识图通常需要一个给定的句子。该领域的方法要么使用 GCN 作为构造块，要么使用不同的架构。</p><p>基于 GCN 的图生成网络包括：分子生成对抗网络（Molecular Generative Adversarial Networks，MolGAN）和深度图生成模型（Deep Generative Models of Graphs，DGMG）；其他图生成网络有 GraphRNN（通过两级循环神经网络使用深度图生成模型）和 NetGAN（结合 LSTM 和 Wasserstein GAN 从基于随机游走的方法中生成图）。</p><h3 id=图时空网络>图时空网络<a hidden class=anchor aria-hidden=true href=#图时空网络>#</a></h3><p>图时空网络同时捕捉时空图的时间和空间依赖。时空图具备全局图结构，每个节点的输入随着时间而改变。例如在交通网络中，使用每个传感器作为节点来连续记录某条道路的交通流动速度，其中交通网络的边由传感器对之间的距离决定。图时空网络的目标是预测未来节点值或标签，或预测时空图标签。近期研究探索了仅使用 GCN、结合 GCN 和 RNN 或 CNN，以及专用于图结构的循环架构。</p><p>基于 GCN 的图时空网络包括：Diffusion Convolutional Recurrent Neural Network (DCRNN)、CNN-GCN、时空 GCN（Spatial Temporal GCN，ST-GCN）。其他图时空网络有 Structural-RNN，一种循环结构化框架。</p><h2 id=应用>应用<a hidden class=anchor aria-hidden=true href=#应用>#</a></h2><p>GNN被广泛应用在社交网络、推荐系统、物理系统、化学分子预测、知识图谱、自然语言处理、计算机视觉（场景图生成、动作识别等）、交通预测等领域。</p><p>常用的数据集如下：</p><p><img loading=lazy src=/img/gnn-dataset.png alt></p><h2 id=未来方向>未来方向<a hidden class=anchor aria-hidden=true href=#未来方向>#</a></h2><ul><li><p>加深网络。深度学习的成功在于深度神经架构。但在图网络中，实证研究表明，随着网络层数增加，模型性能急剧下降。这是由于图卷积的影响，因为它本质上推动相邻节点的表示更加接近彼此。堆叠层数越多，节点考虑的邻居个数也会越多，导致最终所有节点的表示会趋向于一致。这导致了一个问题：加深网络是否仍然是学习图结构数据的好策略？</p></li><li><p>感受野。节点的感受野是指一组节点，包括中心节点和其近邻节点。有些节点可能只有一个近邻，而有些节点却有数千个近邻。如何选择节点的代表性感受野仍然有待探索。</p></li><li><p>可扩展性。当前大部分图神经网络并不能很好地扩展到大规模数据（大型图）上。主要原因是当堆叠一个图卷积的多层时，节点的最终状态涉及其大量近邻节点的隐藏状态，导致反向传播变得非常复杂。</p></li><li><p>动态性和异质性。大多数当前的图神经网络都处理静态同质图，即假设图架构是固定的，而且图的节点和边来自同一个来源。然而，这两个假设在很多情况下是不现实的。在社交网络中，一个新人可能会随时加入，而之前就存在的人也可能退出该社交网络。在推荐系统中，产品可能具有不同的类型，而其输出形式也可能不同，也许是文本，也许是图像。</p></li><li><p>可解释性。由于图通常与其他学科相关，解释图深度学习模型对于决策问题来说是关键。但是，基于图的深度学习模型比其他黑箱模型更难解释，因为图中的节点和边高度关联。</p></li></ul><p>参考综述论文：</p><p><a href=https://arxiv.org/abs/1812.08434>Graph Neural Networks: A Review of Methods and Applications</a>. Jie Zhou, Ganqu Cui, Zhengyan Zhang, Cheng Yang, Zhiyuan Liu, Maosong Sun. 2018.</p><p><a href=https://arxiv.org/abs/1901.00596>A Comprehensive Survey on Graph Neural Networks</a>. Zonghan Wu, Shirui Pan, Fengwen Chen, Guodong Long, Chengqi Zhang, Philip S. Yu. 2019.</p><p><a href=https://arxiv.org/abs/1812.04202>Deep Learning on Graphs</a>: A Survey. Ziwei Zhang, Peng Cui, Wenwu Zhu. 2018.</p></div><footer class=post-footer><ul class=post-tags><li><a href=https://vozhuo.github.io/tags/%E5%9B%BE%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/>图神经网络</a></li></ul><nav class=paginav><a class=prev href=https://vozhuo.github.io/posts/keras-image-classification/><span class=title>« Prev</span><br><span>使用Keras做花卉图像分类</span>
</a><a class=next href=https://vozhuo.github.io/posts/rn-for-object-dection-note/><span class=title>Next »</span><br><span>Relation Networks for Object Detection阅读笔记</span></a></nav><ul class=share-buttons><li><a target=_blank rel="noopener noreferrer" aria-label="share 图神经网络初探 on x" href="https://x.com/intent/tweet/?text=%e5%9b%be%e7%a5%9e%e7%bb%8f%e7%bd%91%e7%bb%9c%e5%88%9d%e6%8e%a2&amp;url=https%3a%2f%2fvozhuo.github.io%2fposts%2fgnn-view%2f&amp;hashtags=%e5%9b%be%e7%a5%9e%e7%bb%8f%e7%bd%91%e7%bb%9c"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M512 62.554V449.446C512 483.97 483.97 512 449.446 512H62.554C28.03 512 0 483.97.0 449.446V62.554C0 28.03 28.029.0 62.554.0H449.446C483.971.0 512 28.03 512 62.554zM269.951 190.75 182.567 75.216H56L207.216 272.95 63.9 436.783h61.366L235.9 310.383l96.667 126.4H456L298.367 228.367l134-153.151H371.033zM127.633 110h36.468l219.38 290.065H349.5z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share 图神经网络初探 on linkedin" href="https://www.linkedin.com/shareArticle?mini=true&amp;url=https%3a%2f%2fvozhuo.github.io%2fposts%2fgnn-view%2f&amp;title=%e5%9b%be%e7%a5%9e%e7%bb%8f%e7%bd%91%e7%bb%9c%e5%88%9d%e6%8e%a2&amp;summary=%e5%9b%be%e7%a5%9e%e7%bb%8f%e7%bd%91%e7%bb%9c%e5%88%9d%e6%8e%a2&amp;source=https%3a%2f%2fvozhuo.github.io%2fposts%2fgnn-view%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM160.461 423.278V197.561h-75.04v225.717h75.04zm270.539.0V293.839c0-69.333-37.018-101.586-86.381-101.586-39.804.0-57.634 21.891-67.617 37.266v-31.958h-75.021c.995 21.181.0 225.717.0 225.717h75.02V297.222c0-6.748.486-13.492 2.474-18.315 5.414-13.475 17.767-27.434 38.494-27.434 27.135.0 38.007 20.707 38.007 51.037v120.768H431zM123.448 88.722C97.774 88.722 81 105.601 81 127.724c0 21.658 16.264 39.002 41.455 39.002h.484c26.165.0 42.452-17.344 42.452-39.002-.485-22.092-16.241-38.954-41.943-39.002z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share 图神经网络初探 on reddit" href="https://reddit.com/submit?url=https%3a%2f%2fvozhuo.github.io%2fposts%2fgnn-view%2f&title=%e5%9b%be%e7%a5%9e%e7%bb%8f%e7%bd%91%e7%bb%9c%e5%88%9d%e6%8e%a2"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM446 265.638c0-22.964-18.616-41.58-41.58-41.58-11.211.0-21.361 4.457-28.841 11.666-28.424-20.508-67.586-33.757-111.204-35.278l18.941-89.121 61.884 13.157c.756 15.734 13.642 28.29 29.56 28.29 16.407.0 29.706-13.299 29.706-29.701.0-16.403-13.299-29.702-29.706-29.702-11.666.0-21.657 6.792-26.515 16.578l-69.105-14.69c-1.922-.418-3.939-.042-5.585 1.036-1.658 1.073-2.811 2.761-3.224 4.686l-21.152 99.438c-44.258 1.228-84.046 14.494-112.837 35.232-7.468-7.164-17.589-11.591-28.757-11.591-22.965.0-41.585 18.616-41.585 41.58.0 16.896 10.095 31.41 24.568 37.918-.639 4.135-.99 8.328-.99 12.576.0 63.977 74.469 115.836 166.33 115.836s166.334-51.859 166.334-115.836c0-4.218-.347-8.387-.977-12.493 14.564-6.47 24.735-21.034 24.735-38.001zM326.526 373.831c-20.27 20.241-59.115 21.816-70.534 21.816-11.428.0-50.277-1.575-70.522-21.82-3.007-3.008-3.007-7.882.0-10.889 3.003-2.999 7.882-3.003 10.885.0 12.777 12.781 40.11 17.317 59.637 17.317 19.522.0 46.86-4.536 59.657-17.321 3.016-2.999 7.886-2.995 10.885.008 3.008 3.011 3.003 7.882-.008 10.889zm-5.23-48.781c-16.373.0-29.701-13.324-29.701-29.698.0-16.381 13.328-29.714 29.701-29.714 16.378.0 29.706 13.333 29.706 29.714.0 16.374-13.328 29.698-29.706 29.698zM160.91 295.348c0-16.381 13.328-29.71 29.714-29.71 16.369.0 29.689 13.329 29.689 29.71.0 16.373-13.32 29.693-29.689 29.693-16.386.0-29.714-13.32-29.714-29.693z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share 图神经网络初探 on facebook" href="https://facebook.com/sharer/sharer.php?u=https%3a%2f%2fvozhuo.github.io%2fposts%2fgnn-view%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H342.978V319.085h66.6l12.672-82.621h-79.272v-53.617c0-22.603 11.073-44.636 46.58-44.636H425.6v-70.34s-32.71-5.582-63.982-5.582c-65.288.0-107.96 39.569-107.96 111.204v62.971h-72.573v82.621h72.573V512h-191.104c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share 图神经网络初探 on whatsapp" href="https://api.whatsapp.com/send?text=%e5%9b%be%e7%a5%9e%e7%bb%8f%e7%bd%91%e7%bb%9c%e5%88%9d%e6%8e%a2%20-%20https%3a%2f%2fvozhuo.github.io%2fposts%2fgnn-view%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zm-58.673 127.703c-33.842-33.881-78.847-52.548-126.798-52.568-98.799.0-179.21 80.405-179.249 179.234-.013 31.593 8.241 62.428 23.927 89.612l-25.429 92.884 95.021-24.925c26.181 14.28 55.659 21.807 85.658 21.816h.074c98.789.0 179.206-80.413 179.247-179.243.018-47.895-18.61-92.93-52.451-126.81zM263.976 403.485h-.06c-26.734-.01-52.954-7.193-75.828-20.767l-5.441-3.229-56.386 14.792 15.05-54.977-3.542-5.637c-14.913-23.72-22.791-51.136-22.779-79.287.033-82.142 66.867-148.971 149.046-148.971 39.793.014 77.199 15.531 105.329 43.692 28.128 28.16 43.609 65.592 43.594 105.4-.034 82.149-66.866 148.983-148.983 148.984zm81.721-111.581c-4.479-2.242-26.499-13.075-30.604-14.571-4.105-1.495-7.091-2.241-10.077 2.241-2.986 4.483-11.569 14.572-14.182 17.562-2.612 2.988-5.225 3.364-9.703 1.12-4.479-2.241-18.91-6.97-36.017-22.23C231.8 264.15 222.81 249.484 220.198 245s-.279-6.908 1.963-9.14c2.016-2.007 4.48-5.232 6.719-7.847 2.24-2.615 2.986-4.484 4.479-7.472 1.493-2.99.747-5.604-.374-7.846-1.119-2.241-10.077-24.288-13.809-33.256-3.635-8.733-7.327-7.55-10.077-7.688-2.609-.13-5.598-.158-8.583-.158-2.986.0-7.839 1.121-11.944 5.604-4.105 4.484-15.675 15.32-15.675 37.364.0 22.046 16.048 43.342 18.287 46.332 2.24 2.99 31.582 48.227 76.511 67.627 10.685 4.615 19.028 7.371 25.533 9.434 10.728 3.41 20.492 2.929 28.209 1.775 8.605-1.285 26.499-10.833 30.231-21.295 3.732-10.464 3.732-19.431 2.612-21.298-1.119-1.869-4.105-2.99-8.583-5.232z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share 图神经网络初探 on telegram" href="https://telegram.me/share/url?text=%e5%9b%be%e7%a5%9e%e7%bb%8f%e7%bd%91%e7%bb%9c%e5%88%9d%e6%8e%a2&amp;url=https%3a%2f%2fvozhuo.github.io%2fposts%2fgnn-view%2f"><svg viewBox="2 2 28 28" height="30" width="30" fill="currentcolor"><path d="M26.49 29.86H5.5a3.37 3.37.0 01-2.47-1 3.35 3.35.0 01-1-2.47V5.48A3.36 3.36.0 013 3 3.37 3.37.0 015.5 2h21A3.38 3.38.0 0129 3a3.36 3.36.0 011 2.46V26.37a3.35 3.35.0 01-1 2.47 3.38 3.38.0 01-2.51 1.02zm-5.38-6.71a.79.79.0 00.85-.66L24.73 9.24a.55.55.0 00-.18-.46.62.62.0 00-.41-.17q-.08.0-16.53 6.11a.59.59.0 00-.41.59.57.57.0 00.43.52l4 1.24 1.61 4.83a.62.62.0 00.63.43.56.56.0 00.4-.17L16.54 20l4.09 3A.9.9.0 0021.11 23.15zM13.8 20.71l-1.21-4q8.72-5.55 8.78-5.55c.15.0.23.0.23.16a.18.18.0 010 .06s-2.51 2.3-7.52 6.8z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share 图神经网络初探 on ycombinator" href="https://news.ycombinator.com/submitlink?t=%e5%9b%be%e7%a5%9e%e7%bb%8f%e7%bd%91%e7%bb%9c%e5%88%9d%e6%8e%a2&u=https%3a%2f%2fvozhuo.github.io%2fposts%2fgnn-view%2f"><svg width="30" height="30" viewBox="0 0 512 512" fill="currentcolor" xmlns:inkscape="http://www.inkscape.org/namespaces/inkscape"><path d="M449.446.0C483.971.0 512 28.03 512 62.554V449.446C512 483.97 483.97 512 449.446 512H62.554C28.03 512 0 483.97.0 449.446V62.554C0 28.03 28.029.0 62.554.0H449.446zM183.8767 87.9921h-62.034L230.6673 292.4508V424.0079h50.6655V292.4508L390.1575 87.9921H328.1233L256 238.2489z"/></svg></a></li></ul></footer></article></main><footer class=footer><span>&copy; 2024 <a href=https://vozhuo.github.io>Vozhuo's Blog</a></span>
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg>
</a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script></body></html>