<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>Python on Vozhuo&#39;s Blog</title>
    <link>https://vozhuo.github.io/tags/python/</link>
    <description>Recent content in Python on Vozhuo&#39;s Blog</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>zh</language>
    <lastBuildDate>Sun, 10 Feb 2019 21:12:53 +0000</lastBuildDate>
    <atom:link href="https://vozhuo.github.io/tags/python/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>自然语言处理和词嵌入</title>
      <link>https://vozhuo.github.io/posts/deep-learning-word-embedding/</link>
      <pubDate>Sun, 10 Feb 2019 21:12:53 +0000</pubDate>
      <guid>https://vozhuo.github.io/posts/deep-learning-word-embedding/</guid>
      <description>&lt;h2 id=&#34;词汇表征&#34;&gt;词汇表征&lt;/h2&gt;
&lt;p&gt;计算机是无法直接认识单词的，所以为了让计算机能更好地理解人类语言，需要将词汇进行表征。之前用到的方法是One-hot表征，即创建一个向量，将对应单词的位置用1表示，其余位置用0表示。这种方法的缺点是无法获得词与词之间的相关性。另一种方法是特征表征，即词嵌入，用不同的特征对单词进行特征化表示。&lt;/p&gt;</description>
    </item>
    <item>
      <title>循环神经网络</title>
      <link>https://vozhuo.github.io/posts/deep-learning-rnn/</link>
      <pubDate>Tue, 29 Jan 2019 14:05:41 +0000</pubDate>
      <guid>https://vozhuo.github.io/posts/deep-learning-rnn/</guid>
      <description>&lt;p&gt;对于序列模型，使用传统的神经网络效果并不好。原因是输入输出数据的长度可能不同，另外这种神经网络结果不能共享从文本不同位置所学习到的特征。循环神经则不存在这两个缺点。在每一个时间步中，循环神经网络会传递一个激活值到下一个时间步中，用于下一时间步的计算。&lt;/p&gt;</description>
    </item>
    <item>
      <title>数据统计——研究生出生日期</title>
      <link>https://vozhuo.github.io/posts/statistics-of-birth-date/</link>
      <pubDate>Sun, 20 Jan 2019 16:48:44 +0000</pubDate>
      <guid>https://vozhuo.github.io/posts/statistics-of-birth-date/</guid>
      <description>&lt;p&gt;最近得到了一份带有班里所有学生身份证号的Excel文件，于是想要统计一下所有同学的出生信息。这里选用xlrd模块读取Excel文件，文件中三个工作表（Sheet）只有第一个有数据，所以读取第一个Sheet的内容。&lt;/p&gt;</description>
    </item>
    <item>
      <title>深度学习之结构化机器学习</title>
      <link>https://vozhuo.github.io/posts/deep-learning-structure-ml/</link>
      <pubDate>Thu, 27 Dec 2018 11:54:54 +0000</pubDate>
      <guid>https://vozhuo.github.io/posts/deep-learning-structure-ml/</guid>
      <description>&lt;h2 id=&#34;评估&#34;&gt;评估&lt;/h2&gt;
&lt;p&gt;在训练机器学习模型时，设置单一数字评估指标可以更好地评估模型。如查准率、召回率和结合两种的F1分数。&lt;/p&gt;
&lt;p&gt;在选择训练、开发、测试集时要遵循一定规则，开发集和测试集的分布要来自同一分布，且随机选取。&lt;/p&gt;</description>
    </item>
    <item>
      <title>深度学习之改善深层神经网络</title>
      <link>https://vozhuo.github.io/posts/deep-learning-improve-nn/</link>
      <pubDate>Thu, 13 Dec 2018 10:06:12 +0000</pubDate>
      <guid>https://vozhuo.github.io/posts/deep-learning-improve-nn/</guid>
      <description>&lt;p&gt;本文主要叙述神经网络的数据集、偏差与方差、正则化、随机失活、归一化输入、梯度消失与梯度爆炸、梯度检验等要点。&lt;/p&gt;
&lt;h2 id=&#34;数据集&#34;&gt;数据集&lt;/h2&gt;
&lt;p&gt;在建立神经网络模型前，我们要将数据集划分为三个部分：训练集、交叉验证集和测试集。欠拟合的情况下，出现高偏差；过拟合的情况下，出现高方差。出现高偏差时，可以使用增加隐藏层数目、加长训练时间等方法解决。出现高方差时，可以使用增加训练数据、正则化等方法解决。&lt;/p&gt;</description>
    </item>
    <item>
      <title>深度学习之神经网络</title>
      <link>https://vozhuo.github.io/posts/deep-learning-nn/</link>
      <pubDate>Thu, 06 Dec 2018 13:02:32 +0000</pubDate>
      <guid>https://vozhuo.github.io/posts/deep-learning-nn/</guid>
      <description>&lt;p&gt;因为此部分在之前的博文中提及，所以不再详细赘述其中原理，代码只展示核心部分。&lt;/p&gt;
&lt;p&gt;激活函数在神经网络中具有重要的地位，常见的激活函数有sigmoid、tanh、ReLU（修正线性单元）和Leaky ReLU等。前两种是饱和激活函数、后两种则是非饱和激活函数，它可以解决“梯度消失”的问题并加快收敛速度。&lt;/p&gt;</description>
    </item>
    <item>
      <title>机器学习之支持向量机</title>
      <link>https://vozhuo.github.io/posts/machine-learning-svm/</link>
      <pubDate>Wed, 28 Nov 2018 19:00:26 +0000</pubDate>
      <guid>https://vozhuo.github.io/posts/machine-learning-svm/</guid>
      <description>&lt;h2 id=&#34;概念&#34;&gt;概念&lt;/h2&gt;
&lt;p&gt;支持向量机（Support Vector Machine，缩写SVM）是一种监督式学习方法，广泛应用于统计分类以及回归分析，和逻辑回归同属于线性分类器。SVM计算出的决策边界与正、负样本保持了足够大的距离，因此SVM是一种大间距分类器。&lt;/p&gt;</description>
    </item>
    <item>
      <title>机器学习之推荐系统</title>
      <link>https://vozhuo.github.io/posts/machine-learning-recommend/</link>
      <pubDate>Thu, 22 Nov 2018 20:08:51 +0000</pubDate>
      <guid>https://vozhuo.github.io/posts/machine-learning-recommend/</guid>
      <description>&lt;h2 id=&#34;概念&#34;&gt;概念&lt;/h2&gt;
&lt;p&gt;很多网站都使用推荐系统预测用户喜欢的内容。以电影资讯网站为例，假设电影有多个特征，那么根据用户对电影的打分，我们可以预测用户可能喜欢那些类型的电影，这就是基于内容的推荐系统。这种优化过程和线性回归类似。&lt;/p&gt;</description>
    </item>
    <item>
      <title>机器学习之异常检测</title>
      <link>https://vozhuo.github.io/posts/machine-learning-detection/</link>
      <pubDate>Thu, 22 Nov 2018 11:02:07 +0000</pubDate>
      <guid>https://vozhuo.github.io/posts/machine-learning-detection/</guid>
      <description>&lt;h2 id=&#34;概念&#34;&gt;概念&lt;/h2&gt;
&lt;p&gt;异常检测是一种识别异常样本的方法，我们需要构建一个概率模型，如果某一样本被认定是正常样本的概率足够小，那么它会被当做异常样本。高斯分布（或称正态分布）模型是异常检测算法最常使用的概率分布模型。&lt;/p&gt;</description>
    </item>
    <item>
      <title>机器学习之主成分分析</title>
      <link>https://vozhuo.github.io/posts/machine-learning-pca/</link>
      <pubDate>Sun, 18 Nov 2018 16:32:17 +0000</pubDate>
      <guid>https://vozhuo.github.io/posts/machine-learning-pca/</guid>
      <description>&lt;h2 id=&#34;概念&#34;&gt;概念&lt;/h2&gt;
&lt;p&gt;主成分分析（Principle Component Analysis，缩写PCA）是一种特征降维技术，也是一种无监督学习算法。另外两种较为常用的降维技术是t-SNE和自编码器。PCA能从冗余特征中提取主要成分，在不太损失模型质量的情况下，提升模型训练速度。&lt;/p&gt;</description>
    </item>
    <item>
      <title>机器学习之K-平均算法</title>
      <link>https://vozhuo.github.io/posts/machine-learning-kmeans/</link>
      <pubDate>Sun, 18 Nov 2018 15:25:17 +0000</pubDate>
      <guid>https://vozhuo.github.io/posts/machine-learning-kmeans/</guid>
      <description>&lt;h2 id=&#34;概念&#34;&gt;概念&lt;/h2&gt;
&lt;p&gt;K-平均算法是一种无监督的聚类算法。无监督学习是一种自由的方式，其训练集不会标明类别，需要算法进行自我归纳。K-平均算法的思想是，对于给定的训练集，按照样本之间距离的大小划分为k个簇。让簇内的点尽量靠在一起，簇与簇之间的距离尽量大。&lt;/p&gt;</description>
    </item>
    <item>
      <title>机器学习之神经网络</title>
      <link>https://vozhuo.github.io/posts/machine-learning-nn/</link>
      <pubDate>Sun, 11 Nov 2018 09:34:17 +0000</pubDate>
      <guid>https://vozhuo.github.io/posts/machine-learning-nn/</guid>
      <description>&lt;h2 id=&#34;前向传播&#34;&gt;前向传播&lt;/h2&gt;
&lt;p&gt;神经网络每层都包含有若干神经元，当信息传递时，第i层神经元接受上层的输入，经激励函数作用后，会产生一个激活向量，此向量将作为下一层神经元的输入值，以此规律向下不断传递。整个过程因为发生顺序是不断地将刺激由前一层传向下一层，故而称之为前向传递。&lt;/p&gt;</description>
    </item>
    <item>
      <title>机器学习之逻辑回归</title>
      <link>https://vozhuo.github.io/posts/machine-learning-logistic-regression/</link>
      <pubDate>Sun, 04 Nov 2018 13:19:44 +0000</pubDate>
      <guid>https://vozhuo.github.io/posts/machine-learning-logistic-regression/</guid>
      <description>&lt;h2 id=&#34;概念&#34;&gt;概念&lt;/h2&gt;
&lt;p&gt;在现实生活中，我们遇到的数据大多数都是非线性的，因此不能用线性回归的方法来进行数据拟合，这就需要用到逻辑回归。逻辑回归虽然名字里带“回归”，但是实际上是一种分类方法，用于两分类问题。基本过程如下：&lt;/p&gt;</description>
    </item>
    <item>
      <title>机器学习之线性回归</title>
      <link>https://vozhuo.github.io/posts/machine-learning-gradient-descent/</link>
      <pubDate>Sat, 27 Oct 2018 16:57:48 +0000</pubDate>
      <guid>https://vozhuo.github.io/posts/machine-learning-gradient-descent/</guid>
      <description>&lt;h2 id=&#34;概念&#34;&gt;概念&lt;/h2&gt;
&lt;p&gt;梯度下降法是一种寻找函数最小值的一阶最优化算法，为找到函数的局部最小值，需要采用与当前点处函数的梯度（或者是近似梯度）的反方向成比例的步长进行迭代搜索。直观地来看，假如我们处于一座山的顶端，想要寻找最快的下山方法。从几何意义上讲，梯度的方向是函数值增加最快的方向，所以梯度的反方向就是函数值下降最快的方向。我们在每一点反复求取梯度，最后到达局部的最小值，就可以下山了。&lt;/p&gt;</description>
    </item>
    <item>
      <title>一周LeetCode习题精选——树</title>
      <link>https://vozhuo.github.io/posts/leetcode-weekend-featured-tree/</link>
      <pubDate>Sun, 21 Oct 2018 14:44:19 +0000</pubDate>
      <guid>https://vozhuo.github.io/posts/leetcode-weekend-featured-tree/</guid>
      <description>&lt;h2 id=&#34;leetcode-226&#34;&gt;LeetCode 226&lt;/h2&gt;
&lt;p&gt;链接：&lt;a href=&#34;https://leetcode.com/problems/invert-binary-tree/description/&#34;&gt;Invert Binary Tree&lt;/a&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Google: 90% of our engineers use the software you wrote (Homebrew), but you can’t invert a binary tree on a whiteboard so fuck off.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;难倒大神的反转二叉树问题，其实这道题并不难，用递归和遍历都可解决。&lt;/p&gt;</description>
    </item>
    <item>
      <title>一周LeetCode习题精选——链表</title>
      <link>https://vozhuo.github.io/posts/leetcode_weekend_featured_ll/</link>
      <pubDate>Sun, 14 Oct 2018 14:36:49 +0000</pubDate>
      <guid>https://vozhuo.github.io/posts/leetcode_weekend_featured_ll/</guid>
      <description>&lt;h2 id=&#34;leetcode-206&#34;&gt;LeetCode 206&lt;/h2&gt;
&lt;p&gt;链接：&lt;a href=&#34;https://leetcode.com/problems/reverse-linked-list/&#34;&gt;Reverse Linked List&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;本题是一道非常基础的反转单链表。首先想到的方法是把链表转换成数组直接逆序，这里不再细说。另外两种方法是递归和迭代。递归方法是指先反转最后两个节点，依次往前至全部反转。迭代法是从左至右反转。&lt;/p&gt;</description>
    </item>
    <item>
      <title>一周LeetCode习题精选——动态规划(2)</title>
      <link>https://vozhuo.github.io/posts/leetcode-weekend-featured-dp2/</link>
      <pubDate>Sun, 07 Oct 2018 13:48:36 +0000</pubDate>
      <guid>https://vozhuo.github.io/posts/leetcode-weekend-featured-dp2/</guid>
      <description>&lt;h2 id=&#34;leetcode-55&#34;&gt;LeetCode 55&lt;/h2&gt;
&lt;p&gt;链接：&lt;a href=&#34;https://leetcode.com/problems/jump-game/description/&#34;&gt;Jump Game&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;本题可以使用动态规划解决。动态规划主要有四个步骤：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;使用递归回溯方法&lt;/li&gt;
&lt;li&gt;使用备忘录方法优化（自顶向下的动态规划）&lt;/li&gt;
&lt;li&gt;消除递归方法（自底向上的动态规划）&lt;/li&gt;
&lt;li&gt;使用其他方法优化时间/空间复杂度&lt;/li&gt;
&lt;/ol&gt;</description>
    </item>
    <item>
      <title>一周LeetCode习题精选——动态规划</title>
      <link>https://vozhuo.github.io/posts/leetcode_weekend_featured_dp/</link>
      <pubDate>Sun, 30 Sep 2018 20:45:55 +0000</pubDate>
      <guid>https://vozhuo.github.io/posts/leetcode_weekend_featured_dp/</guid>
      <description>&lt;h2 id=&#34;leetcode-198&#34;&gt;LeetCode 198&lt;/h2&gt;
&lt;p&gt;链接：&lt;a href=&#34;https://leetcode.com/problems/house-robber/description/&#34;&gt;House Robber&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;本题使用动态规划解决。首先需要分析题目的递归关系：当强盗到达第i间房屋时，他可以选择抢，也可以选择不抢。如果抢劫这间房屋，根据题目要求，他必定没有抢劫第i-1间房屋，但他可能抢劫第i-2间房屋。如果不抢劫第i间房屋，那么他可能抢劫第i-1间房屋。这两个选择造成抢劫得来金钱的不同。设rob(i)为前i间房屋抢劫得来金钱的最大值，第一种需要计算前i-2间房屋抢劫金钱的最大值加上第i间房屋抢劫的金钱。第二种只需要计算前i-1间房屋抢劫金钱的最大值。两者需取其中最大值，由此得出递归关系：&lt;/p&gt;</description>
    </item>
    <item>
      <title>一周LeetCode习题精选</title>
      <link>https://vozhuo.github.io/posts/leetcode_weekend_featured/</link>
      <pubDate>Sun, 23 Sep 2018 19:41:45 +0000</pubDate>
      <guid>https://vozhuo.github.io/posts/leetcode_weekend_featured/</guid>
      <description>&lt;h2 id=&#34;leetcode-208&#34;&gt;LeetCode 208&lt;/h2&gt;
&lt;p&gt;链接：&lt;a href=&#34;https://leetcode.com/problems/implement-trie-prefix-tree/description/&#34;&gt;Implement Trie (Prefix Tree)&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;本题要求构造一个前缀树。前缀树是数据结构中树的一种，用于检索字符串数据集中的值，在自动完成、拼写检查、IP路由等方面都有应用。前缀树节点有两个字段：一个链接到字符串的下一个字符节点child，另一个为布尔值is_end，判断指定节点是否已到末尾。这里需要说一下Python的collections.defaultdict()这个方法，此方法构建了一个类似字典的对象，与普通字典不同的是，在查找字典中不存在key时，普通字典会报错，而defaultdict不会返回错误，而是返回一个默认值。本例会返回一个TrieNode节点，这样省去了在功能方法中新建节点的步骤。本题要求实现三个前缀树的三个功能：插入单词、搜索给定单词是否存在于前缀树以及搜索给定单词是否是前缀树中单词的前缀。&lt;/p&gt;</description>
    </item>
    <item>
      <title>Python爬虫初学</title>
      <link>https://vozhuo.github.io/posts/python_spider_practice/</link>
      <pubDate>Sun, 16 Sep 2018 11:29:17 +0000</pubDate>
      <guid>https://vozhuo.github.io/posts/python_spider_practice/</guid>
      <description>&lt;p&gt;这几天学习了Python爬虫有关的知识，自己做了一个简单的实例：爬取熊猫直播某板块的主播信息。本实例使用Requests +BeautifulSoup和爬虫框架Scrapy两种方法。&lt;/p&gt;
&lt;p&gt;BeautifulSoup可以从HTML或XML文件中提取数据，Requests则用于读取网络资源。虽然Python内置的urllib模块也可以读取网页，但Requests使用起来要更方便。首先需要确定要爬取的URL，这里我选择了熊猫直播的“守望先锋”板块，网址为&lt;a href=&#34;https://www.panda.tv/cate/overwatch&#34;&gt;https://www.panda.tv/cate/overwatch&lt;/a&gt;。先来看一下网页的源码：&lt;/p&gt;</description>
    </item>
    <item>
      <title>使用Python模拟GiWiFi登录</title>
      <link>https://vozhuo.github.io/posts/python_simulate_login/</link>
      <pubDate>Fri, 14 Apr 2017 00:00:00 +0000</pubDate>
      <guid>https://vozhuo.github.io/posts/python_simulate_login/</guid>
      <description>&lt;p&gt;前几天学了Python爬虫的一些基础，就想拿个网站来练练手。我想到了最近一直在用的GiWiFi登录网站，所以就用此网站做模拟登陆。&lt;/p&gt;
&lt;p&gt;我使用Chrome的开发者工具来抓取网页链接信息。随便点击一个网站，就会跳转到GiWiFi的登录界面，如图：
&lt;!-- raw HTML omitted --&gt;&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
